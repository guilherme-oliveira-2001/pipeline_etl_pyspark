# üß™ Teste de Aprendizado: Pipeline ETL com PySpark no Databricks

Este notebook (`Teste Pipeline ETL de API p√∫blica IBGE.ipynb`) √© um experimento pr√°tico desenvolvido para estudar e validar conceitos de constru√ß√£o de pipelines ETL (Extract, Transform, Load) utilizando PySpark dentro do ambiente Databricks.

## üìå Objetivo

Demonstrar o funcionamento de um pipeline ETL b√°sico com as seguintes etapas:

- **Extra√ß√£o** de dados de uma API p√∫blica do IBGE, relativamente simples e b√°sica.
- **Transforma√ß√£o** dos dados com opera√ß√µes PySpark (limpeza, padroniza√ß√£o e agrega√ß√µes)
- **Carga** dos dados transformados em delta table no volume do catalogo.

## ‚öôÔ∏è Tecnologias Utilizadas

- [Databricks](https://www.databricks.com/)
- [Apache Spark (PySpark)](https://spark.apache.org/docs/latest/api/python/)
- Python 3.x
- Notebooks `.ipynb`

## üìÅ Estrutura do Notebook

1. **Configura√ß√£o do ambiente**
   - Inicializa√ß√£o da sess√£o Spark
   - Defini√ß√£o de par√¢metros e caminhos

2. **Extra√ß√£o**
   - Leitura de dados simulados
   - Visualiza√ß√£o inicial

3. **Transforma√ß√£o**
   - Limpeza de dados
   - Enriquecimento e agrega√ß√µes

4. **Carga**
   - Escrita dos dados transformados

## üìö Aprendizados

- Como estruturar um pipeline ETL modular com PySpark
- Boas pr√°ticas de manipula√ß√£o de dados em Spark
- Integra√ß√£o com o ambiente Databricks para testes e visualiza√ß√µes
